{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "1e5dfacec216a49c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install sentencepiece\n",
    "!pip install mecab-ko-dic\n",
    "!pip install mecab-python3\n",
    "!pip install mecab-ko"
   ],
   "id": "aa1da9000d0b3589"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#라이브러리 임포팅\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sentencepiece as spm\n",
    "import mecab"
   ],
   "id": "24656f7e59d83be3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ec0aaa-8214-4fc3-b1a3-4ee9b49aec72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 준비\n",
    "train_data = pd.read_csv('ChatbotData.csv') \n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfcf4207-5880-437a-9de1-66378e0fb683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리\n",
    "#한글, 숫자, 특수문자를 제외한 모든 문자 제거 및 소문자화\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower() # 대문자를 소문자로 변환\n",
    "    sentence = re.sub(r\"([?.!,¿\\\\\\\"'():;-])\", r\" \\1 \", sentence)\n",
    "    #  2 특수문자 양쪽에 공백 추가\n",
    "    sentence = re.sub(r' {2,}', ' ', sentence) # 둘 이상의 공백을 하나의 공백으로 치환\n",
    "    sentence = re.sub(r\"[^ㄱ-ㅎㅏ-ㅣ가-힣0-9?.!,]+\", \" \", sentence) #한글 숫자 특수문자만 남김\n",
    "    sentence = sentence.strip() # 문자열 양 끝 공백 제거\n",
    "    return sentence\n",
    "\n",
    "    \n",
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    questions.append(sentence)\n",
    "\n",
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b411687a-498e-48d7-b40c-f3a42591d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(questions))\n",
    "    f.write('\\n'.join(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51871101-7723-419b-873e-33dff4048763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=all.txt --model_prefix=chatbot --vocab_size=8007 --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS] --user_defined_symbols=[SEP],[CLS],[MASK]\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: all.txt\n",
      "  input_format: \n",
      "  model_prefix: chatbot\n",
      "  model_type: BPE\n",
      "  vocab_size: 8007\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [SEP]\n",
      "  user_defined_symbols: [CLS]\n",
      "  user_defined_symbols: [MASK]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: [UNK]\n",
      "  bos_piece: [BOS]\n",
      "  eos_piece: [EOS]\n",
      "  pad_piece: [PAD]\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: all.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 23645 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [UNK]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [BOS]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [EOS]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [SEP]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [CLS]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [MASK]\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=369706\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1081\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 23645 sentences.\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 23645\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 20693\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13944 min_freq=42\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1055 size=20 all=16167 active=1765 piece=▁거예요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=776 size=40 all=16883 active=2481 piece=▁여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=619 size=60 all=17546 active=3144 piece=▁좋아하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=427 size=80 all=18152 active=3750 piece=▁모\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=358 size=100 all=18881 active=4479 piece=▁전\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=357 min_freq=37\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307 size=120 all=19314 active=1399 piece=▁뭐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=262 size=140 all=19907 active=1992 piece=▁소\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=227 size=160 all=20331 active=2416 piece=▁비\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=206 size=180 all=20687 active=2772 piece=▁행\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=188 size=200 all=21059 active=3144 piece=▁관\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=188 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=172 size=220 all=21413 active=1400 piece=▁재\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=155 size=240 all=21741 active=1728 piece=▁데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=144 size=260 all=22062 active=2049 piece=▁자꾸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=280 all=22443 active=2430 piece=▁고백\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=130 size=300 all=22796 active=2783 piece=▁먼저\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=130 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=122 size=320 all=23129 active=1469 piece=▁헤어진지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=340 all=23459 active=1799 piece=▁버\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=360 all=23675 active=2015 piece=▁돈\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=103 size=380 all=24001 active=2341 piece=▁곳\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=400 all=24397 active=2737 piece=▁함\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=99 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=92 size=420 all=24680 active=1501 piece=▁남자친구\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=440 all=24901 active=1722 piece=다가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=460 all=25157 active=1978 piece=▁사람은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=480 all=25444 active=2265 piece=▁내일\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=500 all=25674 active=2495 piece=리고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=77 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=75 size=520 all=25899 active=1487 piece=▁어떨까요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72 size=540 all=26127 active=1715 piece=▁해도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=560 all=26402 active=1990 piece=▁그만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=580 all=26568 active=2156 piece=▁휴\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64 size=600 all=26754 active=2342 piece=▁항상\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=64 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=620 all=26920 active=1504 piece=▁문제\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=640 all=27183 active=1767 piece=▁상황\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=660 all=27430 active=2014 piece=▁개\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=680 all=27636 active=2220 piece=▁가보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=700 all=27758 active=2342 piece=▁충분히\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=53 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=720 all=27910 active=1540 piece=▁열심히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=740 all=28050 active=1680 piece=▁종\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=760 all=28206 active=1836 piece=▁부모\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=780 all=28339 active=1969 piece=으니까요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=800 all=28484 active=2114 piece=▁부모님\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=47 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=820 all=28589 active=1520 piece=▁헤어지고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=840 all=28721 active=1652 piece=더니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=860 all=28862 active=1793 piece=▁살아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=880 all=28954 active=1885 piece=▁모르는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=900 all=29084 active=2015 piece=▁스스로\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=41 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=920 all=29222 active=1588 piece=▁정리가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=940 all=29333 active=1699 piece=▁끊\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=960 all=29525 active=1891 piece=▁잘하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=980 all=29677 active=2043 piece=▁정도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=1000 all=29823 active=2189 piece=▁붙잡\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=1020 all=29947 active=1604 piece=같아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=1040 all=30075 active=1732 piece=기는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=1060 all=30222 active=1879 piece=드릴게요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=1080 all=30371 active=2028 piece=▁힘내세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=1100 all=30470 active=2127 piece=▁언젠간\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=32 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=1120 all=30569 active=1623 piece=▁받고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=1140 all=30660 active=1714 piece=▁나아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1160 all=30760 active=1814 piece=어야\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1180 all=30874 active=1928 piece=이었을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1200 all=30996 active=2050 piece=▁꿈에\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1220 all=31049 active=1602 piece=여보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=1240 all=31149 active=1702 piece=▁싸우\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1260 all=31170 active=1723 piece=▁냉\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1280 all=31266 active=1819 piece=▁어렵\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1300 all=31340 active=1893 piece=▁만났어\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1320 all=31440 active=1667 piece=아서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1340 all=31568 active=1795 piece=▁알고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1360 all=31627 active=1854 piece=▁힘들죠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1380 all=31719 active=1946 piece=▁미치\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1400 all=31793 active=2020 piece=▁알려줘\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1420 all=31842 active=1637 piece=▁먹을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1440 all=31961 active=1756 piece=▁드디어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1460 all=32021 active=1816 piece=▁경우\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1480 all=32072 active=1867 piece=▁차분\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1500 all=32136 active=1931 piece=▁거기까지\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1520 all=32276 active=1743 piece=▁10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1540 all=32342 active=1809 piece=답니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1560 all=32381 active=1848 piece=▁자연스러운\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1580 all=32485 active=1952 piece=야할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1600 all=32595 active=2062 piece=▁집중\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1620 all=32631 active=1659 piece=▁준비가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1640 all=32663 active=1691 piece=치가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1660 all=32770 active=1798 piece=▁오빠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1680 all=32856 active=1884 piece=▁받았어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1700 all=32865 active=1893 piece=▁걷\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1720 all=32993 active=1763 piece=이요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1740 all=33080 active=1850 piece=▁애랑\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1760 all=33136 active=1906 piece=▁아름다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1780 all=33153 active=1923 piece=고생\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1800 all=33289 active=2059 piece=▁나타\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1820 all=33345 active=1717 piece=▁있고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1840 all=33397 active=1769 piece=▁한동안\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1860 all=33438 active=1810 piece=냐고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1880 all=33544 active=1916 piece=▁다니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1900 all=33597 active=1969 piece=▁없애\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1920 all=33675 active=1752 piece=▁SNS\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1940 all=33692 active=1769 piece=▁사랑하는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1960 all=33746 active=1823 piece=소한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1980 all=33838 active=1915 piece=▁돈을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2000 all=33909 active=1986 piece=▁일상\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2020 all=33954 active=1735 piece=▁소중한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2040 all=33961 active=1742 piece=▁않았어요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2060 all=33998 active=1779 piece=▁헛\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2080 all=34137 active=1918 piece=▁나의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2100 all=34177 active=1958 piece=▁잡고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2120 all=34203 active=1735 piece=▁벗어나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2140 all=34199 active=1731 piece=▁생각나네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2160 all=34187 active=1719 piece=▁이해해주세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2180 all=34254 active=1786 piece=먹고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2200 all=34387 active=1919 piece=▁나올\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2220 all=34427 active=1757 piece=▁샀어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2240 all=34497 active=1827 piece=▁인간\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2260 all=34571 active=1901 piece=▁결정을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2280 all=34575 active=1905 piece=▁없다고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2300 all=34591 active=1921 piece=▁후회가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2320 all=34591 active=1730 piece=▁무시하세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2340 all=34638 active=1777 piece=되는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2360 all=34720 active=1859 piece=▁끝난\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2380 all=34754 active=1893 piece=▁소원\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2400 all=34784 active=1923 piece=▁취향\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2420 all=34823 active=1774 piece=▁됩니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2440 all=34823 active=1774 piece=▁없어서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2460 all=34807 active=1758 piece=▁상대방이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2480 all=34792 active=1743 piece=▁응원합니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2500 all=34823 active=1774 piece=▁합\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2520 all=34915 active=1831 piece=전에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2540 all=34962 active=1878 piece=▁나면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2560 all=34986 active=1902 piece=▁불행\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2580 all=35034 active=1950 piece=▁외국\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2600 all=35088 active=2004 piece=만으로\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2620 all=35122 active=1783 piece=▁마무리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2640 all=35123 active=1784 piece=▁있다고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2660 all=35131 active=1792 piece=▁사랑으로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2680 all=35119 active=1780 piece=▁힘들겠네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2700 all=35152 active=1813 piece=갈까\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2720 all=35235 active=1835 piece=이니\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2740 all=35292 active=1892 piece=▁내요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2760 all=35327 active=1927 piece=▁변명\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2780 all=35368 active=1968 piece=▁이뤄\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2800 all=35414 active=2014 piece=이라고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2820 all=35455 active=1806 piece=▁됐는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2840 all=35452 active=1803 piece=▁아프다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2860 all=35442 active=1793 piece=▁태어난\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2880 all=35451 active=1802 piece=▁생각하면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2900 all=35441 active=1792 piece=▁다르겠지만\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2920 all=35466 active=1798 piece=▁닮\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2940 all=35534 active=1866 piece=라이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2960 all=35654 active=1986 piece=하대\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2980 all=35690 active=2022 piece=▁대출\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3000 all=35716 active=2048 piece=▁살기\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3020 all=35735 active=1804 piece=▁왔네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3040 all=35768 active=1837 piece=▁회식\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3060 all=35845 active=1914 piece=▁가는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3080 all=35844 active=1913 piece=▁되는지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3100 all=35833 active=1902 piece=▁알아차\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3120 all=35828 active=1784 piece=▁재미가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3140 all=35821 active=1777 piece=▁기다리면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3160 all=35817 active=1773 piece=▁있었으면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3180 all=35810 active=1766 piece=▁감사합니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3200 all=35790 active=1746 piece=..\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3220 all=35825 active=1823 piece=걸로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3240 all=35892 active=1890 piece=이스\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3260 all=35943 active=1941 piece=▁기간\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3280 all=35965 active=1963 piece=▁매너\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3300 all=36004 active=2002 piece=▁새해\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3320 all=36042 active=1836 piece=▁여우\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3340 all=36068 active=1862 piece=▁주기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3360 all=36100 active=1894 piece=▁해봤\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3380 all=36171 active=1965 piece=이세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3400 all=36192 active=1986 piece=▁나만의\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3420 all=36187 active=1805 piece=▁만나도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3440 all=36178 active=1796 piece=▁세상은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3460 all=36169 active=1787 piece=▁위해서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3480 all=36164 active=1782 piece=▁후회는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3500 all=36176 active=1794 piece=▁드릴게요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3520 all=36169 active=1802 piece=▁좋아하나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3540 all=36158 active=1791 piece=▁사랑이네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3560 all=36144 active=1777 piece=▁끓\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3580 all=36185 active=1818 piece=▁흥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3600 all=36243 active=1876 piece=료가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3620 all=36318 active=1887 piece=장에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3640 all=36348 active=1917 piece=▁거요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3660 all=36362 active=1931 piece=▁너는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3680 all=36380 active=1949 piece=▁못했\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3700 all=36401 active=1970 piece=▁신기\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3720 all=36417 active=1833 piece=▁입지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3740 all=36430 active=1846 piece=▁축복\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3760 all=36476 active=1892 piece=에서도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3780 all=36517 active=1933 piece=▁계획을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3800 all=36501 active=1917 piece=▁될지도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3820 all=36499 active=1824 piece=▁번호를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3840 all=36489 active=1814 piece=▁아니고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3860 all=36483 active=1808 piece=▁운명이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3880 all=36484 active=1809 piece=▁처음에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3900 all=36479 active=1804 piece=하니까요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3920 all=36470 active=1811 piece=▁사랑에는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3940 all=36458 active=1799 piece=▁있었나요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3960 all=36453 active=1794 piece=▁힘들지요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3980 all=36436 active=1777 piece=▁억지로라도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4000 all=36426 active=1767 piece=▁곱\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4020 all=36450 active=1843 piece=▁찼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4040 all=36508 active=1901 piece=도는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4060 all=36568 active=1961 piece=와서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4080 all=36617 active=2010 piece=표현\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4100 all=36655 active=2048 piece=▁갖지\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4120 all=36672 active=1850 piece=▁놀다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4140 all=36698 active=1876 piece=▁많네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4160 all=36710 active=1888 piece=▁분노\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4180 all=36719 active=1897 piece=▁슈퍼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4200 all=36739 active=1917 piece=▁어둠\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4220 all=36756 active=1852 piece=▁이뻐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4240 all=36762 active=1858 piece=▁좋고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4260 all=36794 active=1890 piece=▁치유\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4280 all=36809 active=1905 piece=▁형편\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4300 all=36849 active=1945 piece=스피싱\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4320 all=36914 active=1906 piece=▁가짐에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4340 all=36897 active=1889 piece=▁궁금할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4360 all=36883 active=1875 piece=▁더러워\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4380 all=36878 active=1870 piece=▁망했어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4400 all=36862 active=1854 piece=▁부딪혔\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4420 all=36851 active=1830 piece=▁실수할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4440 all=36837 active=1816 piece=▁없지만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4460 all=36830 active=1809 piece=▁재회를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4480 all=36827 active=1806 piece=▁치과에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4500 all=36814 active=1793 piece=▁힘들고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4520 all=36818 active=1845 piece=▁나을지도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4540 all=36807 active=1834 piece=▁사랑하기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4560 all=36797 active=1824 piece=▁연락해서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4580 all=36785 active=1812 piece=▁차분하게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4600 all=36778 active=1805 piece=▁되었나봐요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4620 all=36760 active=1821 piece=▁아이스크림\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4640 all=36744 active=1805 piece=▁걱정되겠네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4660 all=36738 active=1799 piece=▁떡\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4680 all=36767 active=1828 piece=▁팀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4700 all=36813 active=1874 piece=두절\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4720 all=36855 active=1880 piece=셨나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4740 all=36922 active=1947 piece=의금\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4760 all=36968 active=1993 piece=힌다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4780 all=36977 active=2002 piece=▁구속\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4800 all=36992 active=2017 piece=▁내내\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4820 all=36990 active=1848 piece=▁떨쳐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4840 all=36995 active=1853 piece=▁미용\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4860 all=37001 active=1859 piece=▁불금\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4880 all=37016 active=1874 piece=▁숨막\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4900 all=37029 active=1887 piece=▁염탐\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4920 all=37053 active=1874 piece=▁잘자\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4940 all=37064 active=1885 piece=▁참석\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4960 all=37083 active=1904 piece=▁한계\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4980 all=37122 active=1943 piece=생인데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5000 all=37173 active=1994 piece=▁가까운\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5020 all=37168 active=1854 piece=▁기억의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5040 all=37164 active=1850 piece=▁드리고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5060 all=37152 active=1838 piece=▁맞춤법\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5080 all=37144 active=1830 piece=▁바빠서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5100 all=37138 active=1824 piece=▁상처도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5120 all=37124 active=1843 piece=▁않는게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5140 all=37117 active=1836 piece=▁유난히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5160 all=37106 active=1825 piece=▁지나가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5180 all=37099 active=1818 piece=▁편하고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5200 all=37085 active=1804 piece=▁혼자인\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5220 all=37104 active=1873 piece=▁관리하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5240 all=37088 active=1857 piece=▁맞추세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5260 all=37071 active=1840 piece=▁생일이네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5280 all=37060 active=1829 piece=▁연락두절\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5300 all=37046 active=1815 piece=▁잊혀지지\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5320 all=37032 active=1839 piece=▁카톡으로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5340 all=37024 active=1831 piece=▁결혼하는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5360 all=37005 active=1812 piece=▁순간이네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5380 all=36989 active=1796 piece=▁힘든가봐요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5400 all=36981 active=1788 piece=▁굳\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5420 all=37002 active=1869 piece=▁엇\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5440 all=37023 active=1890 piece=가의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5460 all=37059 active=1926 piece=네여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5480 all=37096 active=1963 piece=린라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5500 all=37128 active=1995 piece=서와\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5520 all=37162 active=1889 piece=오래\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5540 all=37207 active=1934 piece=질제\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5560 all=37244 active=1971 piece=향을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5580 all=37245 active=1972 piece=▁골프\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5600 all=37249 active=1976 piece=▁나나\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5620 all=37247 active=1861 piece=▁늙어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5640 all=37245 active=1859 piece=▁때요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5660 all=37243 active=1857 piece=▁목적\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5680 all=37252 active=1866 piece=▁반장\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5700 all=37272 active=1886 piece=▁브랜\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5720 all=37288 active=1878 piece=▁손편\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5740 all=37303 active=1893 piece=▁알까\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5760 all=37309 active=1899 piece=▁오셨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5780 all=37309 active=1899 piece=▁이왕\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5800 all=37327 active=1917 piece=▁전학\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5820 all=37338 active=1877 piece=▁지적\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5840 all=37349 active=1888 piece=▁친절\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5860 all=37354 active=1893 piece=▁폭식\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5880 all=37364 active=1903 piece=▁회의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5900 all=37384 active=1923 piece=센터에\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5920 all=37422 active=1908 piece=해졌죠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5940 all=37434 active=1920 piece=▁갈수록\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5960 all=37417 active=1903 piece=▁괜찮길\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5980 all=37404 active=1890 piece=▁꼼수를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6000 all=37392 active=1878 piece=▁다르게\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6020 all=37378 active=1856 piece=▁되었을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6040 all=37369 active=1847 piece=▁만났던\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6060 all=37359 active=1837 piece=▁멈추지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6080 all=37345 active=1823 piece=▁버리는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6100 all=37336 active=1814 piece=▁비밀은\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6120 all=37319 active=1850 piece=▁성공한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6140 all=37314 active=1845 piece=▁싶으면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6160 all=37299 active=1830 piece=▁안좋아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6180 all=37292 active=1823 piece=▁어플을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6200 all=37276 active=1807 piece=▁오해가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6220 all=37269 active=1857 piece=▁이별할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6240 all=37257 active=1845 piece=▁잊지못\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6260 all=37254 active=1842 piece=▁조심히\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6280 all=37237 active=1825 piece=▁지진시\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6300 all=37222 active=1810 piece=▁파도가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6320 all=37204 active=1844 piece=▁헤아릴\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6340 all=37203 active=1843 piece=성이에요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6360 all=37218 active=1858 piece=▁갑작스럽\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6380 all=37209 active=1849 piece=▁금수저로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6400 all=37193 active=1833 piece=▁놀이공원\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6420 all=37174 active=1841 piece=▁마셨는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6440 all=37156 active=1823 piece=▁반가워요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6460 all=37144 active=1811 piece=▁사랑인지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6480 all=37127 active=1794 piece=▁시간내서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6500 all=37112 active=1779 piece=▁어둠에서\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6520 all=37094 active=1838 piece=▁외로움을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6540 all=37080 active=1824 piece=▁인생에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6560 all=37066 active=1810 piece=▁좋아지는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6580 all=37049 active=1793 piece=▁표현하지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6600 all=37031 active=1775 piece=▁헷갈리네\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6620 all=37024 active=1845 piece=▁고백하는게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6640 all=37006 active=1827 piece=▁덜어보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6660 all=36986 active=1807 piece=▁비하하지는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6680 all=36968 active=1789 piece=▁스트레스를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6700 all=36948 active=1769 piece=▁운동하세요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6720 all=36932 active=1832 piece=▁졸업하는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6740 all=36914 active=1814 piece=▁행복하세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6760 all=36894 active=1794 piece=▁사랑하는지는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6780 all=36874 active=1774 piece=▁말씀드려보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6800 all=36876 active=1776 piece=▁눕\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6820 all=36893 active=1859 piece=▁엿\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6840 all=36904 active=1870 piece=▁헥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6860 all=36922 active=1888 piece=구로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6880 all=36952 active=1918 piece=년반\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6900 all=36972 active=1938 piece=두리\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: chatbot.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: chatbot.vocab\n"
     ]
    }
   ],
   "source": [
    "corpus = \"all.txt\"\n",
    "prefix = \"chatbot\"\n",
    "vocab_size = 8000\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#sentencePieceProcessor가 정상적으로 수행되는지 확인\n",
    "vocab_file = \"../../../../../Downloads/chatbot.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n",
    "line = \"안녕하세요 만나서 반갑습니다\"\n",
    "pieces = vocab.encode_as_pieces(line)\n",
    "ids = vocab.encode_as_ids(line)\n",
    "\n",
    "print(line)\n",
    "print(pieces)\n",
    "print(ids)"
   ],
   "id": "d16c053825cf678a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T17:27:59.475291Z",
     "start_time": "2025-09-10T17:27:59.352427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Lexicla Aug를 이용한 데이터 증강\n",
    "import random\n",
    "import gensim\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"ko_c.bin\", binary=True)\n",
    "\n",
    "def lexical_augmentation(sentence_list, wv_model, num_augs=1):\n",
    "    \"\"\"\n",
    "    주어진 문장 리스트에 대해 Lexical Substitution을 적용하여 데이터를 증강하는 함수.\n",
    "\n",
    "    Args:\n",
    "        sentence_list (list): 증강할 원본 문장들의 리스트.\n",
    "        wv_model: Gensim의 KeyedVectors 객체.\n",
    "        num_augs (int): 원본 문장 1개당 생성할 증강 문장의 개수.\n",
    "\n",
    "    Returns:\n",
    "        list: 원본 문장과 증강된 문장이 모두 포함된 리스트.\n",
    "    \"\"\"\n",
    "\n",
    "    # (내부 lexical_sub 함수는 이전과 동일)\n",
    "    def lexical_sub(sentence, wv):\n",
    "        tokens = sentence.split()\n",
    "        valid_tokens = [tok for tok in tokens if tok in wv.key_to_vec]\n",
    "        if not valid_tokens:\n",
    "            return None # 변경: 증강 실패 시 None 반환\n",
    "        selected_tok = random.choice(valid_tokens)\n",
    "        try:\n",
    "            similar_word = wv.most_similar(selected_tok)[0][0]\n",
    "        except KeyError:\n",
    "            return None # 변경: 증강 실패 시 None 반환\n",
    "        return \" \".join([similar_word if tok == selected_tok else tok for tok in tokens])\n",
    "\n",
    "\n",
    "    augmented_corpus = []\n",
    "    print(f\"데이터 증강을 시작합니다 (문장당 최대 {num_augs}개 생성)...\")\n",
    "\n",
    "    # 모든 원본 문장을 우선 корпу스에 포함시킵니다.\n",
    "    augmented_corpus.extend(sentence_list)\n",
    "\n",
    "    for sentence in tqdm(sentence_list):\n",
    "        for _ in range(num_augs):\n",
    "            new_sentence = lexical_sub(sentence, wv_model)\n",
    "            if new_sentence: # 증강에 성공한 경우에만 추가\n",
    "                augmented_corpus.append(new_sentence)\n",
    "\n",
    "    # 최종 중복 제거\n",
    "    augmented_corpus = list(dict.fromkeys(augmented_corpus))\n",
    "    print(f\"데이터 증강 완료! (원본: {len(sentence_list)} 문장 -> 증강 후: {len(augmented_corpus)} 문장)\")\n",
    "\n",
    "    return augmented_corpus\n",
    "\n",
    "# --- 사용 예시 ---\n",
    "# que_train_str, ans_train_str가 있다고 가정\n",
    "# 원본의 약 2배로 증강 (원본 1 + 증강 1)\n",
    "# que_train_augmented = lexical_augmentation(que_train_str, wv, num_augs=1)\n",
    "# ans_train_augmented = lexical_augmentation(ans_train_str, wv, num_augs=1)\n",
    "\n",
    "# 원본의 약 3배로 증강 (원본 1 + 증강 2)\n",
    "# que_train_augmented = lexical_augmentation(que_train_str, wv, num_augs=2)\n",
    "# ans_train_augmented = lexical_augmentation(ans_train_str, wv, num_augs=2)"
   ],
   "id": "2f9be181e6690774",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#train, test 분리\n",
    "que_train, que_test, ans_train, ans_test = train_test_split(\n",
    "                                                    questions,\n",
    "                                                    answers,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    shuffle = True,\n",
    "                                                    random_state = 21)\n",
    "\n",
    "\n",
    "# 4. 전처리된 train데이터를 Lexical aug를 이용해 증강\n",
    "if 'wv' in globals() and wv is not None:\n",
    "    que_train_augmented = lexical_augmentation(que_train, wv, num_augs=2)\n",
    "    ans_train_augmented = lexical_augmentation(ans_train, wv, num_augs=2)\n",
    "    # 질문(Question) 학습 데이터 증강\n",
    "    #que_train = lexical_augmentation(que_train, wv)\n",
    "\n",
    "    # 답변(Answer) 학습 데이터 증강\n",
    "    #ans_train = lexical_augmentation(ans_train, wv)"
   ],
   "id": "3c741a083b6ae3ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "START_TOKEN = [2]\n",
    "END_TOKEN = [3]\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    zeros1 = np.zeros(MAX_LENGTH, dtype=int)\n",
    "    zeros2 = np.zeros(MAX_LENGTH, dtype=int)\n",
    "    sentence1 = START_TOKEN + vocab.encode_as_ids(sentence1) + END_TOKEN\n",
    "    zeros1[:len(sentence1)] = sentence1[:MAX_LENGTH]\n",
    "\n",
    "    sentence2 = START_TOKEN + vocab.encode_as_ids(sentence2) + END_TOKEN\n",
    "    zeros2[:len(sentence2)] = sentence2[:MAX_LENGTH]\n",
    "\n",
    "    tokenized_inputs.append(zeros1)\n",
    "    tokenized_outputs.append(zeros2)\n",
    "  return tokenized_inputs, tokenized_outputs"
   ],
   "id": "fca08a674e1db601"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#인코딩 되어 잘 저장된것을 확인\n",
    "questions_encode, answers_encode = tokenize_and_filter(questions, answers)\n",
    "print(questions_encode[0])\n",
    "print(answers_encode[0])"
   ],
   "id": "4763a693627f7a03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def encode_and_pad(corpus, vocab, max_len):\n",
    "    encoded_corpus = []\n",
    "    for sentence_tokens in corpus:\n",
    "        # 1. 토큰 리스트를 정수 ID 리스트로 변환\n",
    "        ids = [vocab.piece_to_id(token) for token in sentence_tokens]\n",
    "\n",
    "        # 2. 시작 토큰과 종료 토큰 추가\n",
    "        ids = START_TOKEN + ids + END_TOKEN\n",
    "\n",
    "        # 3. 최대 길이에 맞춰 패딩\n",
    "        padded_ids = np.zeros(max_len, dtype=int)\n",
    "        padded_ids[:len(ids)] = ids[:max_len] # 최대 길이를 넘으면 자르기\n",
    "\n",
    "        encoded_corpus.append(padded_ids)\n",
    "\n",
    "    return np.array(encoded_corpus)"
   ],
   "id": "24141674af06fa98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 54,
   "source": [
    "def build_corpus(src_data, tgt_data, tokenizer, max_len=40):\n",
    "    \"\"\"\n",
    "    소스 및 타겟 데이터를 받아 전처리 후 토큰화된 말뭉치를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        src_data (list): 소스 문장 리스트\n",
    "        tgt_data (list): 타겟 문장 리스트\n",
    "        tokenizer (function): 사용할 토크나이저 함수 (e.g., mecab.morphs)\n",
    "        max_len (int): 문장의 최대 토큰 길이\n",
    "\n",
    "    Returns:\n",
    "        tuple: 정제되고 중복이 제거된 (소스 말뭉치, 타겟 말뭉치)\n",
    "    \"\"\"\n",
    "    corpus_pairs = []\n",
    "    for src_sentence, tgt_sentence in zip(src_data, tgt_data):\n",
    "        # 2-1. 문장 정제\n",
    "        src_preprocessed = preprocess_sentence(src_sentence)\n",
    "        tgt_preprocessed = preprocess_sentence(tgt_sentence)\n",
    "\n",
    "        # 2-2. 토큰화\n",
    "        src_tokens = tokenizer.encode_as_pieces(src_preprocessed) # 객체의 메소드를 호출\n",
    "        tgt_tokens = tokenizer.encode_as_pieces(tgt_preprocessed)\n",
    "\n",
    "        # 3. 토큰 개수 필터링\n",
    "        if len(src_tokens) > max_len or len(tgt_tokens) > max_len:\n",
    "            continue\n",
    "\n",
    "        corpus_pairs.append((\" \".join(src_tokens), \" \".join(tgt_tokens)))\n",
    "\n",
    "    # 4. 중복 제거\n",
    "    # 데이터프레임을 사용하여 소스-타겟 쌍을 유지하면서 중복을 안전하게 제거\n",
    "    df = pd.DataFrame(corpus_pairs, columns=['source', 'target'])\n",
    "\n",
    "    # 소스 문장 기준 중복 제거 (첫 번째 등장 쌍 유지)\n",
    "    df = df.drop_duplicates(subset='source', keep='first')\n",
    "\n",
    "    # 타겟 문장 기준 중복 제거 (첫 번째 등장 쌍 유지)\n",
    "    df = df.drop_duplicates(subset='target', keep='first')\n",
    "\n",
    "    # 다시 토큰 리스트 형태로 변환하여 반환\n",
    "    cleaned_src_corpus = [s.split() for s in df['source']]\n",
    "    cleaned_tgt_corpus = [t.split() for t in df['target']]\n",
    "\n",
    "    print(\"데이터 준비 끝!\")\n",
    "    return cleaned_src_corpus, cleaned_tgt_corpus"
   ],
   "id": "e234b65a-b17c-4784-8938-22e18f4cd80a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 4. 함수를 활용하여 que_corpus, ans_corpus 생성\n",
    "# 기존 CSV 파일의 'Q', 'A' 컬럼을 리스트로 변환하여 사용\n",
    "from sklearn.model_selection import train_test_split\n",
    "questions_list = list(train_data['Q'])\n",
    "answers_list = list(train_data['A'])\n",
    "\n",
    "que_corpus, ans_corpus = build_corpus(questions_list, answers_list, vocab, max_len=40)\n",
    "\n",
    "\n",
    "que_corpus_train, que_corpus_test, ans_corpus_train, ans_corpus_test = train_test_split(que_corpus,\n",
    "                                                    ans_corpus,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    shuffle = True,\n",
    "                                                    random_state = 21)\n",
    "\n",
    "que_corpus_train_encoded = encode_and_pad(que_corpus_train, vocab, MAX_LENGTH)\n",
    "ans_corpus_train_encoded = encode_and_pad(ans_corpus_train, vocab, MAX_LENGTH)\n",
    "\n",
    "que_corpus_test_encoded = encode_and_pad(que_corpus_test, vocab, MAX_LENGTH)\n",
    "ans_corpus_test_encoded = encode_and_pad(ans_corpus_test, vocab, MAX_LENGTH)"
   ],
   "id": "86e521c802bf34f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "모델링 시작\n"
   ],
   "id": "d03fb2e07781373a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, questions, answers):\n",
    "        self.inputs = questions\n",
    "        self.dec_inputs = answers[:,:-1]\n",
    "        self.outputs = answers[:,1:]\n",
    "        self.length = len(questions)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return (self.inputs[idx], self.dec_inputs[idx], self.outputs[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "# 3. 전처리된 데이터를 사용하여 DataLoader 생성\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = SequenceDataset(que_corpus_train_encoded, ans_corpus_train_encoded)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "# (선택) 테스트용 DataLoader도 만들 수 있습니다.\n",
    "test_dataset = SequenceDataset(que_corpus_test_encoded, ans_corpus_test_encoded)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"DataLoader 준비 완료!\")"
   ],
   "id": "cdada8046f23003"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.nn import Transformer\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class TFModel(nn.Module):\n",
    "    #ntoken: vocab의 size\n",
    "    #ninp: embedding할 차원의 크기\n",
    "    #nhead: num head\n",
    "    #nhid: feedforward의 차원\n",
    "    #nlayers: layer의 개수\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TFModel, self).__init__()\n",
    "        self.transformer = Transformer(ninp, nhead, dim_feedforward=nhid, num_encoder_layers=nlayers, num_decoder_layers=nlayers,dropout=dropout)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "\n",
    "        self.pos_encoder_d = PositionalEncoding(ninp, dropout)\n",
    "        self.encoder_d = nn.Embedding(ntoken, ninp)\n",
    "\n",
    "        self.ninp = ninp\n",
    "        self.ntoken = ntoken\n",
    "\n",
    "        self.linear = nn.Linear(ninp, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, tgt, srcmask, tgtmask, srcpadmask, tgtpadmask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        tgt = self.encoder_d(tgt) * math.sqrt(self.ninp)\n",
    "        tgt = self.pos_encoder_d(tgt)\n",
    "\n",
    "\n",
    "        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask, src_key_padding_mask=srcpadmask, tgt_key_padding_mask=tgtpadmask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def gen_attention_mask(x):\n",
    "    mask = torch.eq(x, 0)\n",
    "    return mask"
   ],
   "id": "a89a3064fc3d4d11"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b350c3d-4f29-41ef-b0a3-be5a4c8cdeed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "lr = 1e-4\n",
    "model_aug_v1 = TFModel(vocab_size+7, 256, 8, 512, 2, 0.2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8512895d-f14c-4807-972b-3631e7f5b3c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/185 [00:00<?, ?it/s]/opt/conda/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "0.526: 100%|██████████| 185/185 [00:09<00:00, 20.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss: 0.4821202458562078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.485: 100%|██████████| 185/185 [00:09<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | loss: 0.43904361209353887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.397: 100%|██████████| 185/185 [00:09<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | loss: 0.4017047778980152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.359: 100%|██████████| 185/185 [00:08<00:00, 20.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | loss: 0.3657255842879012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.357: 100%|██████████| 185/185 [00:08<00:00, 20.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | loss: 0.3306939820985536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.321: 100%|██████████| 185/185 [00:08<00:00, 20.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | loss: 0.29655188483160894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.319: 100%|██████████| 185/185 [00:08<00:00, 20.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | loss: 0.2633924535802893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.251: 100%|██████████| 185/185 [00:08<00:00, 20.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | loss: 0.23224681132548564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.165: 100%|██████████| 185/185 [00:08<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | loss: 0.20280508092931798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.171: 100%|██████████| 185/185 [00:08<00:00, 20.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | loss: 0.17531315571553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.159: 100%|██████████| 185/185 [00:09<00:00, 20.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | loss: 0.14989565256479623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.096: 100%|██████████| 185/185 [00:09<00:00, 20.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | loss: 0.12697336351549304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.111: 100%|██████████| 185/185 [00:08<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | loss: 0.10629887967496304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.077: 100%|██████████| 185/185 [00:08<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | loss: 0.08812380610285579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.061: 100%|██████████| 185/185 [00:08<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | loss: 0.0721125112997519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.042: 100%|██████████| 185/185 [00:08<00:00, 20.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | loss: 0.05848617553710937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.038: 100%|██████████| 185/185 [00:08<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | loss: 0.047306545360668285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.029: 100%|██████████| 185/185 [00:08<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | loss: 0.0380875149288693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.028: 100%|██████████| 185/185 [00:08<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | loss: 0.030792388400515996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.026: 100%|██████████| 185/185 [00:08<00:00, 20.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 | loss: 0.024830766626306483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.025: 100%|██████████| 185/185 [00:08<00:00, 20.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 | loss: 0.020153650077613626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.019: 100%|██████████| 185/185 [00:08<00:00, 20.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 | loss: 0.01684711688273662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.013: 100%|██████████| 185/185 [00:08<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 | loss: 0.014194571005331504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.014: 100%|██████████| 185/185 [00:08<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 | loss: 0.012273400538676494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.009: 100%|██████████| 185/185 [00:08<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 | loss: 0.010747384380649877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.009: 100%|██████████| 185/185 [00:08<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 | loss: 0.00976073999662657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.009: 100%|██████████| 185/185 [00:08<00:00, 20.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 | loss: 0.008708670332625106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.008: 100%|██████████| 185/185 [00:08<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 | loss: 0.007799176267675451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.008: 100%|██████████| 185/185 [00:08<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 | loss: 0.0074699872248881576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.005: 100%|██████████| 185/185 [00:08<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 | loss: 0.006289432499859784\n"
     ]
    }
   ],
   "source": [
    "epoch = 30\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_aug_v1.train()\n",
    "for i in range(epoch):\n",
    "    batchloss = 0.0\n",
    "    progress = tqdm(dataloader)\n",
    "    for (inputs, dec_inputs, outputs) in progress:\n",
    "        optimizer.zero_grad()\n",
    "        src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).to(device)\n",
    "        src_padding_mask = gen_attention_mask(inputs).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).to(device)\n",
    "        tgt_padding_mask = gen_attention_mask(dec_inputs).to(device)\n",
    "\n",
    "        result = model(inputs.to(device), dec_inputs.to(device), src_mask, tgt_mask, src_padding_mask,tgt_padding_mask)\n",
    "        loss = criterion(result.permute(1,2,0), outputs.to(device).long())\n",
    "        progress.set_description(\"{:0.3f}\".format(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batchloss += loss\n",
    "    print(\"epoch:\",i+1,\"|\",\"loss:\",batchloss.cpu().item() / len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bdeca2b6-283d-4426-8085-dff382df5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model) :\n",
    "    model.train()\n",
    "    \n",
    "    for i in range(model, version):\n",
    "        batchloss = 0.0\n",
    "        progress = tqdm(dataloader)\n",
    "        for (inputs, dec_inputs, outputs) in progress:\n",
    "            optimizer.zero_grad()\n",
    "            src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).to(device)\n",
    "            src_padding_mask = gen_attention_mask(inputs).to(device)\n",
    "            tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).to(device)\n",
    "            tgt_padding_mask = gen_attention_mask(dec_inputs).to(device)\n",
    "    \n",
    "            result = model(inputs.to(device), dec_inputs.to(device), src_mask, tgt_mask, src_padding_mask,tgt_padding_mask)\n",
    "            loss = criterion(result.permute(1,2,0), outputs.to(device).long())\n",
    "            progress.set_description(\"{:0.3f}\".format(loss))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batchloss += loss\n",
    "        print(\"epoch:\",i+1,\"|\",\"loss:\",batchloss.cpu().item() / len(dataloader))\n",
    "\n",
    "    #모델 저장 및 로드\n",
    "    PATH = \"chatbot_model_state_aug_v{}.pth\".format(version)\n",
    "    \n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    print(f\"모델이 {PATH} 경로에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0cc7ac-22b1-420f-9094-3ca4788079c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2008c5-a2c9-40d9-94b7-2aa678753800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#저장된 모델 로드\n",
    "loaded_model = TFModel(vocab_size+7, 256, 8, 512, 2, 0.2).to(device)\n",
    "\n",
    "PATH = \"chatbot_model_state_dict.pth\"\n",
    "loaded_model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "#학습모드가 아닌 eval모드로 전환필수\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"기존 모델 로드 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4b60481-a032-43f3-98d0-85dca5eb6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input = torch.tensor([START_TOKEN + vocab.encode_as_ids(sentence) + END_TOKEN]).to(device)\n",
    "    output = torch.tensor([START_TOKEN]).to(device)\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    model.eval()\n",
    "    for i in range(MAX_LENGTH):\n",
    "        src_mask = model.generate_square_subsequent_mask(input.shape[1]).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(output.shape[1]).to(device)\n",
    "\n",
    "        src_padding_mask = gen_attention_mask(input).to(device)\n",
    "        tgt_padding_mask = gen_attention_mask(output).to(device)\n",
    "\n",
    "        predictions = model(input, output, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1)\n",
    "        # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = torch.LongTensor(torch.argmax(predictions.cpu(), axis=-1))\n",
    "\n",
    "\n",
    "        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if torch.equal(predicted_id[0][0], torch.tensor(END_TOKEN[0])):\n",
    "            break\n",
    "\n",
    "        # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "        output = torch.cat([output, predicted_id.to(device)], axis=1)\n",
    "\n",
    "    return torch.squeeze(output, axis=0).cpu().numpy()\n",
    "\n",
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "    predicted_sentence = vocab.Decode(list(map(int,[i for i in prediction if i < vocab_size+7])))\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24cb88b4-2f0e-462d-9ae0-02b075abb413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 놀고싶다\n",
      "Output: 좋아하는 마음이 복잡할 때은 항상 막히는 .\n",
      "Input: 배고파\n",
      "Output: 뭐라도 드세요 .\n",
      "Input: 고민 상담 해줘\n",
      "Output: 네 말씀해주세요 .\n"
     ]
    }
   ],
   "source": [
    "result = predict(\"놀고싶다\")\n",
    "result = predict(\"배고파\")\n",
    "result = predict(\"고민 상담 해줘\")\n",
    "#매번 잘 나오지는 않지만 일부 잘 만드는 경우가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9372a0eb-f07f-4342-9d6b-0867da566894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict(sentence, model, vocab):\n",
    "    prediction = evaluate(sentence, model, vocab)\n",
    "    # vocab.Decode의 인자는 정수 리스트여야 하므로 map(int, ...)를 사용합니다.\n",
    "    predicted_sentence = vocab.Decode(list(map(int,[i for i in prediction if i < vocab_size+7])))\n",
    "    return predicted_sentence\n",
    "\n",
    "\n",
    "def evaluate(sentence, model, vocab):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input_tensor = torch.tensor([START_TOKEN + vocab.encode_as_ids(sentence) + END_TOKEN]).to(device)\n",
    "    output_tensor = torch.tensor([START_TOKEN]).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(MAX_LENGTH):\n",
    "            src_mask = model.generate_square_subsequent_mask(input_tensor.shape[1]).to(device)\n",
    "            tgt_mask = model.generate_square_subsequent_mask(output_tensor.shape[1]).to(device)\n",
    "\n",
    "            src_padding_mask = gen_attention_mask(input_tensor).to(device)\n",
    "            tgt_padding_mask = gen_attention_mask(output_tensor).to(device)\n",
    "\n",
    "            predictions = model(input_tensor, output_tensor, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1)\n",
    "            predictions = predictions[:, -1:, :]\n",
    "            predicted_id = torch.argmax(predictions, axis=-1)\n",
    "\n",
    "            # if torch.equal(predicted_id[0,0], torch.tensor(END_TOKEN[0])):\n",
    "            #     break\n",
    "            # predicted_id[0,0] 텐서에서 숫자 값을 꺼내 파이썬 정수와 직접 비교\n",
    "            if predicted_id[0,0].item() == END_TOKEN[0]:\n",
    "                break\n",
    "            output_tensor = torch.cat([output_tensor, predicted_id], axis=1)\n",
    "\n",
    "    return torch.squeeze(output_tensor, axis=0).cpu().numpy()\n",
    "\n",
    "\n",
    "# --- [BLEU 점수 계산 함수] ---\n",
    "def calculate_bleu_score(model, questions_corpus, answers_corpus, vocab, weights):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (torch.nn.Module): 평가할 학습된 모델\n",
    "        questions_corpus (list): 토큰화된 질문 문장 리스트\n",
    "        answers_corpus (list): 토큰화된 정답 문장 리스트\n",
    "        vocab (spm.SentencePieceProcessor): SentencePiece 토크나이저\n",
    "    \"\"\"\n",
    "    print(\"BLEU 점수 계산을 시작합니다...\")\n",
    "    \n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    \n",
    "    # SmoothingFunction은 reference에 없는 단어가 hypothesis에 나올 경우 점수가 0이 되는 것을 방지합니다.\n",
    "    smoothie = SmoothingFunction().method1\n",
    "\n",
    "    for que_tokens, ans_tokens in tqdm(zip(questions_corpus, answers_corpus), total=len(questions_corpus)):\n",
    "        # 정답 문장은 이중 리스트 형태(하나의 질문에 여러 정답이 있을 수 있기 때문)\n",
    "        references.append([ans_tokens])\n",
    "        \n",
    "        # 질문 토큰을 다시 문자열로 합쳐 모델의 입력으로 사용\n",
    "        question_str = vocab.decode(que_tokens)\n",
    "        \n",
    "        # 모델 예측\n",
    "        predicted_sentence = predict(question_str, model, vocab)\n",
    "        \n",
    "        # 예측된 문장을 다시 토큰화\n",
    "        hypothesis_tokens = vocab.encode_as_pieces(predicted_sentence)\n",
    "        hypotheses.append(hypothesis_tokens)\n",
    "\n",
    "    # corpus_bleu를 사용하여 전체 테스트셋에 대한 BLEU 점수 계산\n",
    "    # weights는 BLEU-1, 2, 3, 4의 가중치를 의미하며, (0.25, 0.25, 0.25, 0.25)는 BLEU-4를 의미합니다.\n",
    "    bleu_score = corpus_bleu(references, hypotheses, weights, smoothing_function=smoothie)\n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "\n",
    "\n",
    "# --- [함수 실행] ---\n",
    "#평가에는 test 데이터셋을 이용\n",
    "# bleu_score = calculate_bleu_score(model, que_corpus_test, ans_corpus_test, vocab)\n",
    "# print(f\"\\n모델의 BLEU-4 점수: {bleu_score:.4f}\")\n",
    "# print(f\"모델의 BLEU-4 점수 (백분율): {bleu_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48704aed-af13-40e8-a3e6-12415d027b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다양한 가중치에 따른 BLEU SCORE 평가\n",
      "--------------------------------------------------\n",
      "BLEU 점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1933/1933 [01:06<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1 (Individual): 35.96%\n",
      "--------------------------------------------------\n",
      "BLEU 점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1933/1933 [01:06<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-2 (Cumulative): 25.93%\n",
      "--------------------------------------------------\n",
      "BLEU 점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1933/1933 [01:07<00:00, 28.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-3 (Cumulative): 21.52%\n",
      "--------------------------------------------------\n",
      "BLEU 점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1933/1933 [01:06<00:00, 28.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4 (Cumulative): 18.58%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#데이터가 짧은 대화 위주다 보니 n이 높은것보단 낮은게 더 평가점수가 높을것이라 예상 \n",
    "#이를 검증하는 간단한 실험 진행\n",
    "# 테스트하고 싶은 weights를 딕셔너리로 정의\n",
    "weights_to_test = {\n",
    "    \"BLEU-1 (Individual)\": (1, 0, 0, 0),\n",
    "    \"BLEU-2 (Cumulative)\": (0.5, 0.5, 0, 0),\n",
    "    \"BLEU-3 (Cumulative)\": (1/3, 1/3, 1/3, 0),\n",
    "    \"BLEU-4 (Cumulative)\": (0.25, 0.25, 0.25, 0.25)\n",
    "}\n",
    "\n",
    "print(\"다양한 가중치에 따른 BLEU SCORE 평가\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, weights in weights_to_test.items():\n",
    "    score = calculate_bleu_score(model, que_corpus_test, ans_corpus_test, vocab, weights)\n",
    "    print(f\"{name}: {score*100:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c5ac86-3644-4924-b343-f67f3ed15314",
   "metadata": {},
   "source": [
    "예상에 맞게 낮은 n에 가중치를 주는편이 그렇지 않은쪽보다 더 좋은 점수를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "155ee6ff-2b3f-48ce-9e7b-077aeb9275b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다양한 가중치에 따른 BLEU SCORE 평가\n",
      "--------------------------------------------------\n",
      "BLEU 점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1933/1933 [01:06<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1 (Individual): 35.96%\n",
      "--------------------------------------------------\n",
      "BLEU 점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1933/1933 [01:06<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-2 (Cumulative): 18.70%\n",
      "--------------------------------------------------\n",
      "BLEU 점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1933/1933 [01:06<00:00, 29.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-3 (Cumulative): 14.81%\n",
      "--------------------------------------------------\n",
      "BLEU 점수 계산을 시작합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1933/1933 [01:06<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4 (Cumulative): 11.96%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#단순 그램별 스코어 차이도 확인\n",
    "\n",
    "weights_to_test = {\n",
    "    \"BLEU-1 (Individual)\": (1, 0, 0, 0),\n",
    "    \"BLEU-2 (Cumulative)\": (0, 1, 0, 0),\n",
    "    \"BLEU-3 (Cumulative)\": (0, 0, 1, 0),\n",
    "    \"BLEU-4 (Cumulative)\": (0, 0, 0, 1)\n",
    "}\n",
    "\n",
    "print(\"다양한 가중치에 따른 BLEU SCORE 평가\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, weights in weights_to_test.items():\n",
    "    score = calculate_bleu_score(model, que_corpus_test, ans_corpus_test, vocab, weights)\n",
    "    print(f\"{name}: {score*100:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04cb19c-d034-4377-b9ac-668cc6d40893",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
